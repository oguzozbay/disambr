#+title: NEDR - Named Entity Disambiguation in R
#+author: Stanislav A. Vlasov
#+email: stanislav.a.vlasov@gmail.com
# ------------------------------------------------------------------------------

#+PROPERTY: header-args:R :comments link  :session

Description: file:readme.org

* Make & Deploy
#+BEGIN_SRC emacs-lisp
  ;; tangle source code
  (org-babel-tangle)
  ;; run package deployment scripts
  (let ((org-confirm-babel-evaluate nil))
	(save-excursion
	  (org-babel-goto-named-src-block "document")
	  (org-babel-execute-src-block)))
#+END_SRC

** Package documentation
:PROPERTIES:
:ID:       org:g01ja7119ri0
:END:
#+BEGIN_SRC R :tangle R/disambr.r
  #' @details
  #' This package provides a framework for disambiguating named entities (e.g., authors in large bibliometric databases)
  #' Package provides following main functions
  #' - disambr.read
  #' - disambr.guate
  #' This is work in progress. Please, file an issues or suggestion if you have any.
  #' @keywords internal
  "_PACKAGE"
#+END_SRC
** Set .Rprofile (developer enviroment)
*** CRAN Packages
:PROPERTIES:
:ID:       org:ihcia7119ri0
:END:
#+BEGIN_SRC R :tangle .Rprofile
  ## --------------------------------------------------------------------------------
  ## First load default packages getOption("defaultPackages")
  ## Otherwise it will add it at the end which can mask some funcitons
  .First.sys()


  ## some packages installations read .Rprofile loops the install
  current_wd <- getwd()
  setwd("~/")

  ## --------------------------------------------------------------------------------
  ## Load or Install Packages
  ## --------------------------------------------------------------------------------
  for(pkg in c('devtools'
             , 'roxygen2'
             , 'xml2'
             , 'tibble'
             , 'stringi'
             , 'stringr'
             , 'stringdist'
             , 'digest'
             , 'magrittr'
             , 'lubridate'
             , 'plyr'
             , 'pipeR'
             , 'ggplot2'
             , 'pbapply'
             , 'microbenchmark'
             , 'data.table'
             , 'dplyr'))
      if(!require(pkg, character.only = TRUE)) {
          install.packages(pkg, repos = 'http://cloud.r-project.org')
          require(pkg, character.only = TRUE) }


  ## restore current working directore
  setwd(current_wd)

  ## --------------------------------------------------------------------------------
  library(disambr)

  ## update.packages(ask = FALSE, repos = 'http://cloud.r-project.org')

#+END_SRC
*** My Packages
:PROPERTIES:
:ID:       org:hzuia7119ri0
:END:
#+BEGIN_SRC R :results silent :session :tangle no
  ## --------------------------------------------------------------------------------
  ## Load My pakcages
  ## --------------------------------------------------------------------------------
  ## detach(package:romRDS, unload = TRUE)
  ## remove.packages("romRDS")
  if (!require("romRDS", character.only = TRUE)) {
    if(!require("devtools")) {
      install.packages("devtools"
                     , repos = 'http://cloud.r-project.org'
                     , dependencies = TRUE)
      require("devtools", character.only = TRUE)
    }
    install_github("stasvlasov/romRDS")
    require("romRDS", character.only = TRUE)
  }
  ## --------------------------------------------------------------------------------
#+END_SRC
** Set up package
#+name: document
#+BEGIN_SRC R :results none :tangle no

  .First.sys()

  ## --------------------------------------------------------------------------------
  ## Load or Install Packages
  ## --------------------------------------------------------------------------------
  for(pkg in c('devtools'
             , 'roxygen2'
             , 'xml2'
             , 'tibble'
             , 'stringi'
             , 'stringr'
             , 'stringdist'
             , 'digest'
             , 'magrittr'
             , 'lubridate'
             , 'plyr'
             , 'pipeR'
             , 'ggplot2'
             , 'microbenchmark'
             , 'data.table'
             , 'dplyr'))
    if(!require(pkg, character.only = TRUE)) {
      install.packages(pkg, repos = 'http://cloud.r-project.org')
      require(pkg, character.only = TRUE)
    }
  ## --------------------------------------------------------------------------------

  ## Describint package
  ## --------------------------------------------------------------------------------

  ## Include packages:
  package.packages <- c(
      "data.table"
    , "magrittr"
    , "stringi"
    , "stringr"
    , "tibble"
    , "xml2"
    , "dplyr")

  ## Print current packages verstions
  ## package.packages %>%
  ##     sapply(function(pkg)
  ##     paste0(pkg, " (>= ", packageVersion(pkg), ")"), USE.NAMES = FALSE) %>%
  ##     cat(sep = "\n")

  ## Adjust verstions manually
  package.packages.man.ver  <- c(
      "data.table (>= 1.12)"
    , "magrittr (>= 1.5)"
    , "stringi (>= 1.4)"
    , "stringr (>= 1.4)"
    , "dplyr (>= 0.8)"
    , "tibble (>= 2.0)"
    , "xml2 (>= 1.0)"
  )

  ## make description
  list(Package = "disambr"
     , Title  = "NEDR - Named Entity Disambiguation in R"
     , Description = "NEDR - Named Entity Disambiguation in R"
     , `Authors@R` = c(person(given = c("Stanislav" ,"A.") , family = "Vlasov"
                     , email = "stanislav.a.vlasov@gmail.com"
                     , role = c("aut", "cre"))
              , person(given = c("Olmo", "R."), family = "van den Akker"
                     , email = "ovdakker@gmail.com"
                     , role = "aut")
              , person(given = "Sacha", family = "Epskamp"
                     , email = "sacha.epskamp@gmail.com"
                     , role = "aut"))
     , Imports = paste(package.packages.man.ver
                     , collapse = ", ")
     , Depends = "R (>= 3.4)"
     , Version = "0.02"
     , Date = Sys.Date()) %>% use_description()

  use_lgpl_license(name = "Stanislav Vlasov")

  use_tidy_description()

  ## ----------------------------------------------------------------------------
  ## Update name spaces and documentation for functions
  roxygenise()


  ## This function is a wrapper for the ‘roxygen2::roxygenize()’ but also load the package
  ## document()

  ## ----------------------------------------------------------------------------
  ## Set up TestThat
  usethis::use_testthat()
#+END_SRC
** Deploy package
#+BEGIN_SRC R :results silent :tangle no
  ## Deploy
  ## --------------------------------------------------------------------------------
  install(".")

  install_github("stasvlasov/disambr")

  ## Test
  ## --------------------------------------------------------------------------------
  library("disambr")

  ## Remove
  ## --------------------------------------------------------------------------------
  detach(package:and, unload = TRUE)
  remove.packages("disambr")

#+END_SRC



* Functions
** disambr_read
:PROPERTIES:
:ID:       org:1p6ja7119ri0
:END:
#+BEGIN_SRC R :tangle R/disambr_read.r
  ##' Stops process unless cond is true
  ##' @param cond 
  ##' @param message.if.false 
  ##' @param stop.if.false 
  ##' @param return.if.true 
  ##' @param return.if.false 
  ##' @return 
  ##' 
  ##' @export 
  stop.unless <- function(cond
                        , message.if.false = paste("cond in not TRUE")
                        , stop.if.false = TRUE
                        , return.if.true = TRUE
                        , return.if.false = isFALSE(return.if.true)) {
      if(isTRUE(cond)) {
          return(return.if.true)
      } else if(isTRUE(stop.if.false)){
          stop(message.if.false, call. = FALSE)
      } else {
          warning(message.if.false, call. = FALSE)
          return(return.if.false)
      }
  }

  ##' Returns vector of file paths from path(s) recursively
  ##' @param files.path Path(s) where the files are
  ##' @param recursive Whether to look in subfolders recursively
  ##' @return Vector of file paths from path(s) recursively
  ##' 
  ##' @md
  ##' @importFrom magrittr %>%
  ##' @export 
  parse.files.path <- function(files.path, recursive = TRUE) {
      stop.unless(is.character(files.path), "Files path shoud be a character string!")
      lapply(files.path, function(file.path) {
          if(stop.unless(file.exists(file.path)
                       , paste(file.path, " - does not exist!")
                       , stop.if.false = FALSE
                       , return.if.true = FALSE)) {
              NULL
          } else if(dir.exists(file.path)) {
              dir(file.path
                , full.names = TRUE
                , recursive = recursive)
          } else {
              file.path
          }
      }) %>% unlist %>% normalizePath %>% unique
  }


  ##' Reads the data for disambiguation
  ##' @param files.path Path to data. You can specify almost everything
  ##' @inheritDotParams 
  ##' @return 
  ##' 
  ##' @md 
  ##' @export 
  disambr.read <- function(files.path) {
      files.path <- parse.files.path(files.path)
      data.list <- lapply(files.path, disambr.read.file)
      ## TODO: check for consistensy between files
      ## TODO: break data into chunks
      wos.publication <- data.table::rbindlist(data.list, fill=TRUE)
      ## TODO: Combind attributes from files
      attributes(wos.publication)$disambr.set.unit <- "publication"
      attributes(wos.publication)$disambr.set.unit.ids.self <- TRUE
      wos.author <- disambr_eject_authors(wos.publication)
      wos.publication[, c("AU", "AF", "C1", "RP", "EM", "RI", "OI") := NULL]
      attributes(wos.author)$disambr.set.unit <- "person"
      attributes(wos.author)$disambr.set.unit.ids.self <- TRUE
      wos.reference <- disambr_eject_references(wos.publication)
      wos.publication[, "CR" := NULL]
      attributes(wos.reference)$disambr.set.unit <- "reference"
      attributes(wos.reference)$disambr.set.unit.ids.self <- TRUE
      return(list(wos.publication, wos.author, wos.reference))
  }


  ## my.file2 <- "../data/new_export/savedrecs-ms-recent.txt"
  ## dt <- disambr.read(my.file2)


  disambr.read.file <- function(f) {
      f.extention <- tools::file_ext(f)
      switch(f.extention
           , "tsv" = disambr.read.tsv(f)
             ## here we can add reading from .txt wos files
           , "txt" = disambr.read.tsv(f)
           , message("No procedure is defined for the extention: ", f.extention
                   , "\n\\->Skipping file: ", f))
  }

  disambr.read.tsv <- function(f) {
      ## check tsv file type base on first line
      first.line <- readLines(f, n = 1
                            , warn = FALSE
                            , skipNul = TRUE)
      header <- parse.tsv.wos.header(first.line)
      if(!isFALSE(header)) {
          disambr.read.tsv.wos(f, header)
      } else {
          ## here we can add more tsv types
          NULL
      }
  }

  parse.tsv.wos.header <- function(first.line) {
      header <- stri_split_fixed(first.line, "\t")[[1]]
      if( ## check if at least 10 fields two big letters
          sum(stri_detect_regex(header, "^[A-Z0-9]{2}$")) > 10 &&
          ## check if main fields are present
          all(c('AU', 'TI') %in% header)) {
          stri_extract_first_regex(header, "[A-Z0-9]{2}")
      } else {FALSE}
  }

  disambr.read.tsv.wos <- function(f, header) {
      s <- read.to.utf8(f)
      s <- recode.return.characters(s, f)
      dat <- fread(text = s
                 , skip = 1
                 , strip.white = TRUE
                 , header = FALSE
                 , col.names = header
                 , select = 1:length(header)
                   ## , colClasses = rep("character", length(header))
                 , quote=""
                 , keepLeadingZeros = FALSE
                 , encoding = "UTF-8"
                 , sep = "\t")
      ## this should be ejected
      ## dat$AU <- disambr.read.tsv.wos.parse.authors(dat$AU
      ##                                            , dat$EM
      ##                                            , dat$RP)
      ## dat$AF <- disambr.read.tsv.wos.parse.AF(dat$AF)
      ## set attrib (file, funcall, meanning of the fields and data scheme)
      ## this also can be a separate function to set atribute to data
      attributes(dat)$disambr.read.call <- "disambr.read.tsv.wos"
      attributes(dat)$disambr.read.file.md5 <- tools::md5sum(f)
      attributes(dat)$disambr.set.unit <- "publication"
      attributes(dat)$disambr.set.unit.ids.self <- TRUE
      return(dat)
  }





  ## disambr.read.tsv.wos.parse.authors <- function(au, em, rp) {
  ##     au <- stri_split_fixed(au, ";")
  ##     em <- stri_split_fixed(em, ";")
  ##     rp <- stri_split_fixed(rp, ";")
  ##     parse.a <- function(authrs, emails) {
  ##         authrs <- stri_trim(authrs)
  ##         emails <- stri_trim(emails)
  ##         reprints <- stri_trim(reprints)
  ##         reprints <- stri_replace_first_regex(authrs, "\\s+(corresponding author).*", "")
  ##         reprints <- stri_trim(reprints)
  ##         reprints <- unique(reprints)
  ##         last.name <- stri_extract_first_regex(authrs, "^.+(?=,)")
  ##         initials <- stri_extract_first_regex(authrs, "(?<=, )[A-Z]+")
  ##         if(length(emails) == length(authrs)) {
  ##             emails <- emails
  ##         } else if(length(emails) == length(reprints)) {
  ##             ## assume same names
  ##             emails <- emails[match(authrs, reprints)]
  ##         } else if(length(emails) == 1) {
  ##             emails <- emails[ifelse(authrs == reprints[1], 1, NA)]
  ##         } else {
  ##             emails <- ifelse(authrs == reprints[1], emails, NA)
  ##         }
  ##         mapply(function(x, y, z)
  ##             list(initials = x
  ##                , last.name = y
  ##                , email = z)
  ##           , initials
  ##           , last.name
  ##           , email
  ##           , SIMPLIFY = FALSE
  ##           , USE.NAMES = FALSE)
  ##     }
  ##     lapply(au, parse.a)
  ## }

  ## disambr.read.tsv.wos.parse.AU <- function(au) {
  ##     au <- stri_split_fixed(au, ";")
  ##     parse.a <- function(a) {
  ##         a <- stri_trim(a)
  ##         last.name <- stri_extract_first_regex(a, "^.+(?=,)")
  ##         initials <- stri_extract_first_regex(a, "(?<=, )[A-Z]+")
  ##         mapply(function(x, y) list(initials = x, last.name = y)
  ##              , initials
  ##              , last.name
  ##              , SIMPLIFY = FALSE
  ##              , USE.NAMES = FALSE)
  ##     }
  ##     lapply(au, parse.a)
  ## }

  read.to.utf8 <- function(f, bytes.to.check = 2^14) {
      ## read file as raw bytes (not to Assume any encodings)
      bin <- readBin(f, raw(), n = file.size(f))
      ## check first 2^14 bytes for encoding
      encoding <- stringi::stri_enc_detect2(bin[1:bytes.to.check])[[1]][[1]][1]
      if(is.na(encoding)) {
          message("Could not detect encoding of file: ", f)
          s <- rawToChar(bin, multiple = FALSE)
      } else if(!(encoding %in% iconvlist())) {
          message("Does not know how to convert from ", encoding, "for file: ", f)
      } else if(encoding == "UTF8") {
          s <- rawToChar(bin, multiple = FALSE)
      } else {
          ## message("Converting to utf-8")
          s <- iconv(list(NULL, bin), from = encoding, to = "UTF-8")
      }
      return(s)
  }

  ## stringi::stri_enc_detect2(NULL)[[1]][[1]][1]
  ## stringi::stri_enc_detect2(NA)[[1]][[1]][1]
  ## stringi::stri_enc_detect2(123)[[1]][[1]][1]
  ## stringi::stri_enc_detect2("")[[1]][[1]][1]
  ## stringi::stri_enc_detect2("sadf")[[1]][[1]][1]

  recode.return.characters <- function(s, assoc.file = NA) {
      has.return.chars <- function(s, test.first.n.char = 10^4) {
          s <- stri_sub(s, to = test.first.n.char)
          any(stri_detect_regex(s, "\\r"))
      }
      if(has.return.chars(s)) {
          message("'\\r' characters in the file: ", assoc.file
                , "\n Removing to fix 'datatable::fread'")
          s <- stri_replace_all_regex(s, "\\R+", "\n")
      }
      return(s)
  }




  ## utils

  ##' Makes list of each element of l
  ##' @param l sequence or list
  ##' @param l.name same name will be applies to each element
  ##' @return list of lists
  ##' 
  ##' @export 
  disambr_listify_list <- function(l, l.name = NULL) {
      if(isTRUE(l.name == "")) l.name =  NULL
      ## case when all are 1 length (vector or list of single length elements)
      lapply(l, function(x) {
          x <- list(x)
          names(x) <- l.name
          return(x)
      })
  }


  ##' cbinds lists and names each element as name of each list in ...
  ##' @param ... Lists to cbin
  ##' @return Lists
  ##' @export 
  disambr_cbind_lists <- function(...) {
      lists <- eval(...)
      lists_n <- length(lists)
      lists_names <- names(lists)
      cbind_list <- disambr_listify_list(lists[[1]], lists_names[1])
      for (i in 2:lists_n) {
          cbind_list <- 
              mapply(c
                   , cbind_list
                   , disambr_listify_list(lists[[i]], lists_names[i])
                   , SIMPLIFY = FALSE)
      }
      return(cbind_list)
  }


  ## parsers

  ##' Parses AU column of WoS saved records export
  ##' @param record.au a record string from AU column
  ##' @return data.table
  ##' 
  ##' @md 
  disambr_eject_authors_parse_au <- function(record_au) {
      author_name <- stringi::stri_split_fixed(record_au, "; ")[[1]]
      author_last_name <-
          stringi::stri_extract_first_regex(author_name, "^[^,]+")
      author_initials <-
          stringi::stri_extract_first_regex(author_name, "(?<=, )[A-Z]+")
      data.table::data.table(author_name = author_name
                           , author_last_name = author_last_name
                           , author_initials = author_initials
                           , author_order = 1:length(author_name))
  }


  ## tests

  ## "Tilly, TB; Nelson, MT; Chakravarthy, KB; Shira, EA; Debrose, MC; Grabinski, CM; Salisbury, RL; Mattie, DR; Hussain, SM" %>% 
  ## disambr_eject_authors_parse_au




  ##' Parses AF (author full name) column of WoS saved records export
  ##' @param record.au a record string from AF column
  ##' @return Data.table
  disambr_eject_authors_parse_af <- function(record_af) {
      name <- stringi::stri_split_fixed(record_af, "; ")[[1]]
      last_name <- stringi::stri_extract_first_regex(name, "^[^,]+")
      first_names <- stringi::stri_extract_first_regex(name, "(?<=, ).*")
      first_names <-
          stringi::stri_split_fixed(first_names, " ", omit_empty = TRUE)
      ## first.full.name is first name without dot
      first_full_name <-
          lapply(first_names, function(n) {
              n[!stringi::stri_detect_regex(n, "\\.$")][1]
          })
      ## return
      data.table::data.table(
                      author_full_name = name
                    ## , author_last_name = last_name 
                    , author_first_names = first_names
                    , author_first_full_name =  first_full_name)
  }


  ## test
  ## "Tilly, Trevor B.; Nelson, M. Tyler; Chakravarthy, Karthik B.; Shira, Emily A.; Debrose, Madeline C.; Grabinski, Christin M.; Salisbury, Richard L.; Mattie, David R.; Hussain, Saber M." %>%
  ## disambr_eject_authors_parse_af


  ##' Parses RP (reprint author) column of WoS saved records export
  ##' @param record_rp a record string from RP column
  ##' @return Data.table with two columns -  author_name and affiliations
  disambr_eject_authors_parse_rp <- function(record_rp) {
      record_rp_init <- ""
      authors_table <-
          data.table::data.table(author_name = character(0)
                               , affiliations = character(0))
      while(record_rp != record_rp_init) {
          record_rp_init <- record_rp
          record_rp_split <- 
              stringi::stri_match_first_regex(
                           record_rp
                         , "\\s*([^()]+)\\s+\\((corresponding author|reprint author)\\)([^;]+)")
          authors <-
              stringi::stri_split_fixed(record_rp_split[1,2], "; ")[[1]]
          affiliation <-
              stringi::stri_replace_first_regex(
                           record_rp_split[1,4], "^[\\s,.;]+", "")
          for (author in authors) {
              ## check if author is already in the list
              authors_table_match <-
                  authors_table$author_name %in% author
              if(any(authors_table_match)) {
                  ## add affiliation to affiliations of author
                  ## the data.table way..
                  authors_table[authors_table_match
                              , affiliations :=
                                    list(c(unlist(affiliations), affiliation))]
              } else {
                  ## add new author with affiliation otherwise
                  authors_table <-
                      data.table::rbindlist(
                                      list(authors_table
                                         , list(author_name = author
                                              , affiliations =
                                                    list(affiliation))))
              }
          }
          record_rp <-
              stringi::stri_replace_first_regex(
                           record_rp
                         , "[^()]+\\((corresponding author|reprint author)\\)[^;]+[;]", "")
      }
      ## results are not printed but the data.table is returned
      return(authors_table)
  }

  ## "Guesmi, S (corresponding author), Natl Agron Inst Tunisia INAT, 43 Ave Charles Nicolle, Tunis 1082, Tunisia.; Guesmi, S; Sghaier, H (corresponding author), Sidi Thabet Technopk, Natl Ctr Nucl Sci & Technol, Lab Energy & Matter Dev Nucl Sci LR16CNSTN02, Sidi Thabet 2020, Tunisia.; Sghaier, H (corresponding author), Sidi Thabet Technopk, Lab Biotechnol & Nucl Technol LR16CNSTN01, Sidi Thabet 2020, Tunisia.; Sghaier, H (corresponding author), Sidi Thabet Technopk, Lab Biotechnol & Biogeo Resources Valorizat LR11E, Sidi Thabet 2020, Tunisia." %>%
  ## disambr_eject_authors_parse_rp %>% print

  ## "" %>%
  ## disambr_eject_authors_parse_rp %>% nrow


  ##' Parses EM (email) column of WoS saved records export
  ##' @param record_em  a record string from EM column
  ##' @param record_au_table a data_tabe after parsing AU column with disambr_eject_authors_parse_au
  ##' @param record_rp_table a data_tabe after parsing RP column with disambr_eject_authors_parse_rp
  ##' @return Data.table with columns - author_name, affiliations and email
  disambr_eject_authors_parse_em <- function(record_em
                                           , record_au_table
                                           , record_rp_table) {
      emails <- stringi::stri_split_fixed(record_em, "; ")[[1]]
      if (length(emails) == 1 && emails == "") {
          ## in case there are no emails
          record_au_table[, author_email := NA]
      } else if (length(emails) == nrow(record_rp_table)) {
          ## assume that emails corresponds RP authors
          record_au_table[match(record_rp_table$author_name, author_name)
                        , author_email := emails]
      } else if (length(emails) == nrow(record_au_table)) {
          ## assume that emails corresponds AU authors
          record_au_table[, author_email := emails]
      } else if (nrow(record_rp_table) != 0) {
          ## in other cases just use first email for first RP author
          record_au_table[match(record_rp_table$author_name, author_name)[1]
                        , author_email := emails[1]]
      } else {
          ## if no RP assignt to first in AU
          record_au_table[1, author_email := emails[1]]
      }
      ## we do not need to return things as it updates record_au_table
      return(record_au_table)
  }


  ## tests
  ## disambr_eject_authors_parse_em(
  ## record_em = "a"
  ## , record_au_table = data.table(author_name = c(1,2,3,4))
  ## , record_rp_table = data.table(author_name = c(3))
  ## ) %>% print




  ##' Parses C1 (author adress/affiliation) column of WoS saved records export
  ##' @param record_c1 a record string from RP column
  ##' @return Data.table with two columns -  author_name and affiliations
  disambr_eject_authors_parse_c1 <- function(record_c1
                                           , table_af = NULL) {
      record_c1_init <- ""
      authors_table <-
          data.table::data.table()
      while(record_c1 != record_c1_init) {
          record_c1_init <- record_c1
          record_c1_piece <- 
              stringi::stri_match_first_regex(
                           record_c1, "\\s*\\[([^\\[\\]]+)\\]\\s+([^;]+)\\s*")
          authors <-
              stringi::stri_split_fixed(record_c1_piece[1,2], "; ")[[1]]
          affiliation <- record_c1_piece[1,3]
          for (author in authors) {
              ## check if author is already in the list
              authors_table_match <-
                  authors_table$author_full_name %in% author
              if(any(authors_table_match)) {
                  ## add affiliation to affiliations of author
                  ## the data.table way..
                  authors_table[authors_table_match
                              , affiliations :=
                                    list(c(unlist(affiliations), affiliation))]
              } else {
                  ## add new author with affiliation otherwise
                  authors_table <-
                      data.table::rbindlist(list(authors_table
                                               , list(author_full_name = author
                                                    , affiliations = list(affiliation))))
              }
          }
          record_c1 <-
              stringi::stri_replace_first_regex(
                           record_c1, "\\s*\\[[^\\[\\]]+\\][^;]+[;]", "")
      }
      ## merge with table_af if provided
      if(length(table_af) != 0) {
          return(authors_table[table_af
                             , on = "author_full_name"
                             , .(affiliations)])
      } else {
          return(authors_table)
      }
  }



  ## "[Wang, Menglei; Li, Shunyi; Zhu, Rencheng; Zhang, Ruiqin] Zhengzhou Univ, Sch Ecol & Environm, Zhengzhou 450001, Peoples R China; [Wang, Menglei] Zhengzhou Univ, Sch Chem Engn, Zhengzhou 450001, Peoples R China; [Zu, Lei; Wang, Yunjing; Bao, Xiaofeng] Chinese Res Inst Environm Sci, State Environm Protect Key Lab Vehicle Emiss Cont, Beijing 100012, Peoples R China" %>%
  ## disambr_eject_authors_parse_c1


  ## "[Wang, Menglei; Li, Shunyi; Zhu, Rencheng; Zhang, Ruiqin] Zhengzhou Univ, Sch Ecol & Environm, Zhengzhou 450001, Peoples R China; [Wang, Menglei] Zhengzhou Univ, Sch Chem Engn, Zhengzhou 450001, Peoples R China; [Zu, Lei; Wang, Yunjing; Bao, Xiaofeng] Chinese Res Inst Environm Sci, State Environm Protect Key Lab Vehicle Emiss Cont, Beijing 100012, Peoples R China" %>%
  ## disambr_eject_authors_parse_c1(disambr_eject_authors_parse_af("Wang, Menglei; Li, Shunyi; Zhu, Rencheng; Zhang, Ruiqin; Zu, Lei; Wang, Yunjing; Bao, Xiaofeng"))






  ##' Parses RI (researcher_id) column of WoS saved records export
  ##' @param record_ri a record string from RP column
  ##' @param table_af 
  ##' @return Data.table with columns - author_full_name and author_researcher_id 
  disambr_eject_authors_parse_ri <- function(record_ri
                                           , table_af = NULL) {
      if(record_ri != "") {
          authors <- stringi::stri_split_fixed(record_ri, "; ")[[1]]
          authors_list <- lapply(authors, function(author) {
              author_split <- stringi::stri_split_fixed(author, "/", n = 2)[[1]]
              list(author_full_name = author_split[1]
                 , author_researcher_id = author_split[2])
          })
          authors_table <- data.table::rbindlist(authors_list)
      } else {
          authors_table <- data.table::data.table(author_full_name = character()
                                                , author_researcher_id = character())
      }
      ## merge with table_af if provided
      if(length(table_af) != 0) {
          return(authors_table[table_af
                             , on = "author_full_name"
                             , .(author_researcher_id)])
      } else {
          return(authors_table)
      }
  }

  ## "Girabent, Montserrat/B-8536-2008; Maydeu-Olivares, Alberto/B-5178-2010" %>%
  ## disambr_eject_authors_parse_ri


  ##' Parses OI (ORCID) column of WoS saved records export
  ##' @param record_RI a record string from OI column
  ##' @return Data.table with columns - author_full_name and author_orcid
  disambr_eject_authors_parse_oi <- function(record_oi
                                           , table_af = NULL) {
      if(record_oi != "") {
          authors <- stringi::stri_split_fixed(record_oi, "; ")[[1]]
          authors_list <- lapply(authors, function(author) {
              author_split <- stringi::stri_split_fixed(author, "/", n = 2)[[1]]
              list(author_full_name = author_split[1]
                 , author_orcid = author_split[2])
          })
          authors_table <- data.table::rbindlist(authors_list)
      } else {
          authors_table <- data.table::data.table(author_full_name = character()
                                                , author_orcid = character())
      }
      ## merge with table_af if provided
      if(length(table_af) != 0) {
          return(authors_table[table_af
                             , on = "author_full_name"
                             , .(author_orcid)])
      } else {
          return(authors_table)
      }
  }


  ## "Estrela, Pedro/0000-0001-6956-1146; Maxted, Grace/0000-0002-6816-9107; Rainbow, Joshua/0000-0003-3911-928X; Richtera, Lukas/0000-0002-8288-3999; Moschou, Despina/0000-0001-9175-5852" %>% disambr_eject_authors_parse_oi


  ## related fields (as in Web of Science Field Tags 2018-06-27)
  ## au
  ## af full names
  ## - ba book
  ## - bf book
  ## - ca gp group author (usually organization or group name)
  ## - be editors
  ## c1 adresses
  ## rp reprint address (one you contact for reprint copy)
  ## em emails
  ## ri researcher ID
  ## oi ORCID Identifier (Open Researcher and Contributor ID)
  ## eject authors table (after combining initiall export tables)
  disambr_eject_authors <- function(wos_data_table
                                  , list_of_author_fields =
                                        c("author_order"
                                        , "author_short_name"
                                        , "author_initials"
                                        , "author_last_name"
                                        , "author_full_name"
                                        , "author_first_names"
                                        , "author_first_full_name"
                                        , "author_email"
                                        , "author_researcher_id"
                                        , "author_orcid"
                                        , "author_affiliations")) {
      authors_tables <- list()
      ## AU
      if(any(c("author_order"
             , "author_short_name"
             , "author_last_name"
             , "author_initials"
             , "author_email") %in% list_of_author_fields) &&
         "AU" %in% names(wos_data_table)) {
          authors_tables$au <-
              lapply(wos_data_table$AU
                   , disambr_eject_authors_parse_au)

      }
      ## AF
      if(any(c("author_full_name"
             , "author_first_names"
             , "author_first_full_name"
             , "author_researcher_id"
             , "author_orcid"
             , "author_affiliations") %in% list_of_author_fields) &&
         "AF" %in% names(wos_data_table)) {
          authors_tables$af <-
              lapply(wos_data_table$AF
                   , disambr_eject_authors_parse_af)
      }

      ## RP
      if(any(c("author_email") %in% list_of_author_fields) &&
         "RP" %in% names(wos_data_table)) {
          ## save RP separately as it is different order from AU
          rp <-
              lapply(wos_data_table$RP
                   , disambr_eject_authors_parse_rp)
      }

      ## EM
      if(any(c("author_email") %in% list_of_author_fields) &&
         all(c("AU", "EM", "RP") %in% names(wos_data_table))) {
          ## disambr_eject_authors_parse_em updates authors_tables$au
          ## so no need to save it
          mapply(disambr_eject_authors_parse_em
               , wos_data_table$EM
               , authors_tables$au
               , rp
               , SIMPLIFY = FALSE
               , USE.NAMES = FALSE)
      }

      ## C1
      ## if(any(c("author_affiliations") %in% list_of_author_fields) &&
      ##    all(c("C1", "AF") %in% names(wos_data_table))) {
      ##     authors_tables$c1 <-
      ##         mapply(disambr_eject_authors_parse_c1
      ##              , wos_data_table$C1
      ##              , authors_tables$af
      ##              , SIMPLIFY = FALSE)
      ## }

      ## RI
      if(any(c("author_researcher_id") %in% list_of_author_fields) &&
         "RI" %in% names(wos_data_table)) {
          authors_tables$ri <-
              mapply(disambr_eject_authors_parse_ri
                   , wos_data_table$RI
                   , authors_tables$af
                   , SIMPLIFY = FALSE
                   , USE.NAMES = FALSE)
      }

      ## OI
      if(any(c("author_orcid") %in% list_of_author_fields) &&
         "OI" %in% names(wos_data_table)) {
          authors_tables$oi <-
              mapply(disambr_eject_authors_parse_oi
                   , wos_data_table$OI
                   , authors_tables$af
                   , SIMPLIFY = FALSE
                   , USE.NAMES = FALSE)
      }
      ## remove duplicated columns
      authors_tables <- 
          lapply(authors_tables, rbindlist, idcol = "paper_id")
      authors_table <- do.call(cbind, c(authors_tables, list(deparse.level = 0)))
      authors_table_names <- 
          stringi::stri_replace_first_regex(names(authors_table), "^[^\\.]+\\.", "")
      authors_table_select <- which(!duplicated(authors_table_names))
      authors_table_new_names <- authors_table_names[authors_table_select]
      authors_table <- authors_table[, authors_table_select, with = FALSE]
      names(authors_table) <- authors_table_new_names
      return(authors_table)
  }

  ## test
  ## my.file2 <- "../data/new_export/savedrecs-ms-recent.txt"
  ## dt <- disambr.read(my.file2)[[1]]
  ## dt %>% disambr_eject_authors

  ## testing dt merge
  ## a <- data.table(name = c("a", "b", "c"), order = c(1,2,3))
  ## b <- data.table(named = c("c", "b", "c"), affil = c("b-adfsa","c-sadfsd"))
  ## cbind(a, b, check.names = FALSE)

  ## ----------------------------------------------------------------------------





  ## CR (Cited References)

  disambr_parse_references <- function(record_cr) {
      references <- stringi::stri_split_fixed(record_cr, "; ")[[1]]
      references_list <- stringi::stri_split_fixed(references, ", ")
      references_list <-
          lapply(references_list, function(ref) {
              first_author_name <- ref[1]
              year <- ref[2]
              outlet <- ref[3]
              ref_tail <- ref[-c(1:3)]
              vol <- stringi::stri_extract_first_regex(ref_tail, "^V(\\d+)")
              vol <- vol[!sapply(vol, is.na)]
              page <- stringi::stri_extract_first_regex(ref_tail, "^P(\\d+)")
              page <- page[!sapply(page, is.na)]
              doi <- stringi::stri_extract_first_regex(ref_tail, "^DOI \\[*(.*)\\]*")
              doi <- doi[!sapply(doi, is.na)]

              list(first_author_name = ref[1]
                 , year = ref[2]
                 , outlet = ref[3]
                 , vol = vol
                 , page = page
                 , doi = doi)
          })
      suppressWarnings(rbindlist(references_list))
  }

  ## "Allen C, 2017, ENVIRON SCI-NANO, V4, P741, DOI 10.1039/c7en90014g; Baek YW, 2011, SCI TOTAL ENVIRON, V409, P1603, DOI 10.1016/j.scitotenv.2011.01.014; Baker GL, 2008, TOXICOL SCI, V101, P122, DOI 10.1093/toxsci/kfm243; Bergstrom U, 2015, J TOXICOL ENV HEAL A, V78, P645, DOI 10.1080/15287394.2015.1017682; Bhushan B, 2011, PROG MATER SCI, V56, P1, DOI 10.1016/j.pmatsci.2010.04.003; Biswas P, 2005, J AIR WASTE MANAGE, V55, P708, DOI 10.1080/10473289.2005.10464656; Bitterle E, 2006, CHEMOSPHERE, V65, P1784, DOI 10.1016/j.chemosphere.2006.04.035; Bondarenko O, 2013, ARCH TOXICOL, V87, P1181, DOI 10.1007/s00204-013-1079-4; Bonner J. C., 2003, ENV HLTH PERSPECT, V111, P1289; Brossell D, 2013, J AEROSOL SCI, V63, P75, DOI 10.1016/j.jaerosci.2013.04.012; Clift MJD, 2011, ARCH TOXICOL, V85, P723, DOI 10.1007/s00204-010-0560-6; Cohen J, 2013, NANOTOXICOLOGY, V7, P417, DOI 10.3109/17435390.2012.666576; Cohen JM, 2014, PART FIBRE TOXICOL, V11, DOI 10.1186/1743-8977-11-20; Comouth A, 2013, J AEROSOL SCI, V63, P103, DOI 10.1016/j.jaerosci.2013.04.009" %>% disambr_parse_references

  disambr_eject_references <- function(wos_data_table) {
      if("CR" %in% names(wos_data_table)) {
          references_list <-
              lapply(wos_data_table$CR, disambr_parse_references)
          references_table <-
              rbindlist(references_list, idcol = "paper_id")
      }
      references_table
  }



  ## my.file2 <- "../data/new_export/savedrecs-ms-recent.txt"
  ## dt <- disambr.read(my.file2)[[1]]
  ## dt %>% disambr_eject_references


  ## my.dir <- '../data'
  ## my.dir.small <- '../data/Journals in Mathematical Psychology'
  ## my.dir.large <- '/mnt/md5/data/wos/wos-sci-expanded.firm-names-query.analytical-instruments'
  ## my.dir.huge <- '/mnt/md5/data/wos'


  ## my.file <- '../data/Journals in Mathematical Psychology/Applied Psychological Measurement.txt' 
  ## my.file1 <- "/mnt/md5/data/wos/wos-sci-expanded.firm-names-query.analytical-instruments/LN Public NAICS records from 10001 to 10500.txt"
  ## my.file2 <- "../data/new_export/savedrecs-ms-recent.txt"
  ## my.files <-
      ## c('../data/Journals in Mathematical Psychology/Applied Measurement in Education.txt'
      ## , '../data/Journals in Mathematical Psychology/Applied Psychological Measurement.txt')


#+END_SRC

** tests

#+BEGIN_SRC R :results none :session :tangle no
  my.dir <- '../data'
  my.dir.small <- '../data/Journals in Mathematical Psychology'
  my.dir.large <- '/mnt/md5/data/wos/wos-sci-expanded.firm-names-query.analytical-instruments'
  my.dir.huge <- '/mnt/md5/data/wos'

  my.file <- '../data/Journals in Mathematical Psychology/Applied Psychological Measurement.txt' 
  my.file1 <- "/mnt/md5/data/wos/wos-sci-expanded.firm-names-query.analytical-instruments/LN Public NAICS records from 10001 to 10500.txt"
  my.files <-
      c('../data/Journals in Mathematical Psychology/Applied Measurement in Education.txt'
      , '../data/Journals in Mathematical Psychology/Applied Psychological Measurement.txt')


  ## ----------------------------------------------------------------------------

  my.dat <- disambr.read(my.dir)

  my.dat <- disambr.read(my.file)

  attributes(my.dat[[1]])

  my.dat <- disambr.read("../data/new_export")

  my.dat[[1]]$RP[1:4]
  my.dat[[1]]$EM[1:4]

  my.dat <- 
      my.dat %>%
      disambr.get.different.authors


  my.dat[[2]]


  my.dat %>% 
      disambr.get.different.authors %>% 
      disambr.get.similar.initials %>%
      disambr.get.similar.last.names


  dat <- disambr.read(my.file)

  dat %>% extract(1) %>% disambr.get.different.authors


  ## new testing
  d <- disambr.read("../data/wos-researchers-ids")

  d <- d[[1]][1:1000,] %>% list

  d.done <- 
      d %>% 
      disambr.get.different.authors %>% 
      disambr.get.similar.initials  %>%


  d.done %>% length

  d.done2 %>% length

  d.done2[[4]] %>% nrow

  d.done2 <- 
      d.done %>%
      disambr.get.similar.last.names

  saveRDS(d.done2, "../data/d.done2.rds")




  disambr.eva <- function(data) {
      data %>% 
          disambr.get.different.authors %>% 
          disambr.get.similar.initials %>%
          disambr.get.similar.last.names
  }

  ## Usage
  disambr.eva(data)


  disambr.get.different.authors <- disambr.define.procedure(data %>% 
                                                            get(publication) %>%
                                                            for.each %>%
                                                            get(person = author))

  ## or
  disambr.get.different.authors <- disambr.define.procedure(data$
                                                            publication$
                                                            person(author))





  list(data = my.dat
     , similar.initials = set.similar.initials) %>% 
      disambr.get.similar.last.names


  set.different.authors <- disambr.get.different.authors(my.dat)

  set.similar.initials <- 
      list(data = my.dat
         , different.authors = set.different.authors) %>% 
      disambr.get.similar.initials





#+END_SRC

Testing help

#+BEGIN_SRC R :results none :session :tangle no
  options(browser="firefox")
  help(disambr.read, help_type = "html")
#+END_SRC

** testthat

#+BEGIN_SRC R :results none :session :tangle tests/testthat/test.stop.unless.r :mkdirp yes
test_that("stop.unless", {
      expect_warning(stop.unless(FALSE, "Lala", FALSE))
      expect_error(stop.unless(FALSE))
      expect_true(stop.unless(TRUE))
      expect_false(stop.unless("sdfasdf", stop.if.false = FALSE))
      expect_true(stop.unless("sdfasdf", stop.if.false = FALSE, return.if.true = FALSE))
  })
#+END_SRC


#+BEGIN_SRC R :results none :session :tangle tests/testthat/test.parse.files.path.r :mkdirp yes
    test_that("parse.files.path", {
          expect_error(parse.files.path(3423))
          expect_warning(parse.files.path(c(".", "gibirish file")))
          expect_is(parse.files.path("."), "character")
          ## empty dirs
          tmp.dir <- "test_dir_for_parse.files.path"
          dir.create(tmp.dir, showWarnings = FALSE)
          expect_equal(parse.files.path(tmp.dir), character(0))
          file.remove(tmp.dir)
      })
#+END_SRC

** EVA Algorithm
#+name: 
#+BEGIN_SRC R :tangle R/disambr_eva.r
  ##' Returns sets of people ids that are defenetely different based on co-authorship
  ##' @param sets 
  ##' @param procedures 
  ##' @inheritDotParams 
  ##' @return 
  ##' 
  ##' @md 
  ##' @importFrom magrittr %>%
  ##' @import magrittr data.table dplyr stringr
  ##' @export 
  disambr.get.different.authors <- function(sets, procedures = NULL) {
      message("Starting disambr.get.different.authors...")
      if(!is.list(sets)) stop("sets should be list!")
      focal.set <- sets %>%
          extract(sapply(.,attr, "disambr.set.unit") == "person") %>%
          ## TODO: implement extraction from different data type
          extract2(1)
      new.set <- focal.set %>%
          {split(1:nrow(.), .$paper_id)}
      ## set set's attributes
      attributes(new.set)$disambr.set.unit <- "person.distinct"
      attributes(new.set)$disambr.set.unit.ref.md5 <- digest(focal.set, "md5")
      return(c(sets, list(new.set)))
  }

  ## my.file2 <- "../data/new_export/savedrecs-ms-recent.txt"
  ## dt <- disambr.read(my.file2) %>% disambr.get.different.authors
  ## dt[[4]]



  ##' Returns set of people with similar initials
  ##' @param sets 
  ##' @param procedures 
  ##' @inheritDotParams 
  ##' @return 
  ##' 
  ##' @md 
  ##' @importFrom magrittr %>%
  ##' @import magrittr data.table dplyr stringr
  ##' @export 
  disambr.get.similar.initials <- function(sets, procedures = NULL) {
      message("Starting disambr.get.similar.initials...")
      ## sapply(sets,attr, "disambr.set.unit")
      set.different.authors <-
          sets %>%
          extract(sapply(.,attr, "disambr.set.unit") == "person.distinct") %>%
          extract2(1)
      set.data <-sets %>%
          extract(sapply(.,attr, "disambr.set.unit") == "person") %>%
          extract2(1)
      ## procedurs
      subset.similar.initials <- function(comb) {
          a <- set.different.authors[[comb[1]]]
          b <- set.different.authors[[comb[2]]]
          expand.grid(a, b)
      }
      new.set <- combn(1:length(set.different.authors), 2
                     , simplify = FALSE
                       ## , FUN = subset.similar.initials
                       )
      message("...combn produced ", length(new.set), " pairs of pubs")
      new.set <- pblapply(new.set, subset.similar.initials)
      message("...subset.similar.initials is done")
      new.set <- data.table::rbindlist(new.set)
      message("...rbindlist produced ", nrow(new.set), " pairs")
      new.set <- dplyr::mutate(new.set
                             , initials.dist =
                                   stringdist(set.data$author_initials[Var1]
                                            , set.data$author_initials[Var2]
                                            , method = "lv"))
      new.set <- dplyr::filter(new.set, initials.dist < 2)
      attributes(new.set)$disambr.set.unit <- "similar.initials"
      return(c(sets, list(new.set)))
  }


  ## my.file2 <- "../data/new_export/savedrecs-ms-recent.txt"
  ## dt <- disambr.read(my.file2) %>%
      ## disambr.get.different.authors %>%
      ## disambr.get.similar.initials
  ## dt[[5]]



  ##' Returns set of people with similar last names
  ##' @param sets 
  ##' @param procedures 
  ##' @inheritDotParams 
  ##' @return 
  ##' 
  ##' @md 
  ##' @importFrom magrittr %>%
  ##' @import magrittr data.table dplyr stringr
  ##' @export 
  disambr.get.similar.last.names <- function(sets, procedures = NULL) {
      message("Starting disambr.get.similar.last.names...")
      ## TODO: extract teh set that we need here (person, dyads)
      set.similar.initials <- sets %>%
          extract(sapply(.,attr, "disambr.set.unit") == "similar.initials") %>%
          extract2(1)
      set.data <-sets %>%
          extract(sapply(.,attr, "disambr.set.unit") == "person") %>%
          extract2(1)
      new.set <-
          dplyr::mutate(
                     set.similar.initials
                   , last.name.dist =
                         stringdist(set.data$author_last_name[Var1]
                                  , set.data$author_last_name[Var2]
                                  , method = "dl"))
      new.set <- dplyr::filter(new.set, last.name.dist < 2)
      attributes(new.set)$disambr.set.unit <- "similar.last.names"
      return(c(sets, list(new.set)))
  }

  ## my.file2 <- "../data/new_export/savedrecs-ms-recent.txt"
  ## dt <- disambr.read(my.file2) %>%
      ## disambr.get.different.authors %>%
      ## disambr.get.similar.initials %>%
      ## disambr.get.similar.last.names
  ## dt[[6]]


  ##' Returns set of people with save email addresses
  ##' @param sets 
  ##' @param procedures 
  ##' @inheritDotParams 
  ##' @return 
  ##' 
  ##' @md 
  ##' @importFrom magrittr %>%
  ##' @import magrittr data.table dplyr stringr
  ##' @export 
  disambr.get.same.email <- function(sets, procedures = NULL) {
      message("Starting disambr.get.same.email...")
      ## TODO: extract teh set that we need here (person, dyads)
      similar.last.names <- sets %>%
          extract(sapply(.,attr, "disambr.set.unit") == "similar.last.names") %>%
          extract2(1)
      set.data <-sets %>%
          extract(sapply(.,attr, "disambr.set.unit") == "person") %>%
          extract2(1)
      new.set <-
          similar.last.names %>% 
          dplyr::mutate(same.email = mapply(function(var1, var2)
                            set.data$author_email[var1] == set.data$author_email[var2]
                            , Var1, Var2))
      ## new.set <- dplyr::filter(new.set, last.name.dist < 2)
      attributes(new.set)$disambr.set.unit <- "same.email"
      return(c(sets, list(new.set)))
  }

  ## my.file2 <- "../data/new_export/savedrecs-ms-recent.txt"
  ## dt <- disambr.read(my.file2) %>%
      ## disambr.get.different.authors %>%
      ## disambr.get.similar.initials %>%
      ## disambr.get.similar.last.names %>% 
      ## disambr.get.same.email




  ##' Returns set of people with save email addresses
  ##' @param sets 
  ##' @param procedures 
  ##' @inheritDotParams 
  ##' @return 
  ##' 
  ##' @md 
  ##' @importFrom magrittr %>%
  ##' @import magrittr data.table dplyr stringr
  ##' @export 
  disambr.get.same.coauthor <- function(sets, procedures = NULL) {
      message("Starting disambr.get.same.email...")
      ## TODO: extract teh set that we need here (person, dyads)
      similar.last.names <- sets %>%
          extract(sapply(.,attr, "disambr.set.unit") == "similar.last.names") %>%
          extract2(1)
      set.data <-sets %>%
          extract(sapply(.,attr, "disambr.set.unit") == "person") %>%
          extract2(1)
      fun <- function(var1, var2) {
          any(set.data[paper_id %in% paper_id[var1] &
                       !(author_name %in% author_name[var1])]$author_name %in% 
              set.data[paper_id %in% paper_id[var2] &
                       !(author_name %in% author_name[var2])]$author_name)
      }
      new.set <-
          similar.last.names %>% 
          dplyr::mutate(
                     same.co.author = mapply(fun, Var1, Var2))
      ## new.set <- dplyr::filter(new.set, last.name.dist < 2)
      attributes(new.set)$disambr.set.unit <- "same.email"
      return(c(sets, list(new.set)))
  }

  ## my.file2 <- "../data/new_export/savedrecs-ms-recent.txt"
  ## dt <- disambr.read(my.file2) %>%
      ## disambr.get.different.authors %>%
      ## disambr.get.similar.initials %>%
      ## disambr.get.similar.last.names %>% 
      ## disambr.get.same.coauthor

  ## dt[[7]]

  ##' Returns set of people with save email addresses
  ##' @param sets 
  ##' @param procedures 
  ##' @inheritDotParams 
  ##' @return 
  ##' 
  ##' @md 
  ##' @importFrom magrittr %>%
  ##' @import magrittr data.table dplyr stringr
  ##' @export 
  disambr.get.same.affiliation <- function(sets, procedures = NULL) {
      message("Starting disambr.get.same.affiliation...")
      ## TODO: extract teh set that we need here (person, dyads)
      similar.last.names <- sets %>%
          extract(sapply(.,attr, "disambr.set.unit") == "similar.last.names") %>%
          extract2(1)
      set.data <-sets %>%
          extract(sapply(.,attr, "disambr.set.unit") == "person") %>%
          extract2(1)
      new.set <-
          similar.last.names %>% 
          dplyr::mutate(same.affiliations =
                            mapply(function(var1, var2)
                                any(set.data$author_affiliations[var1] %in% 
                                    set.data$author_affiliations[var2])
                            , Var1, Var2))
      ## new.set <- dplyr::filter(new.set, last.name.dist < 2)
      attributes(new.set)$disambr.set.unit <- "same.affiliation"
      return(c(sets, list(new.set)))
  }

  ## my.file2 <- "../data/new_export/savedrecs-ms-recent.txt"
  ## dt <- disambr.read(my.file2) %>%
      ## disambr.get.different.authors %>%
      ## disambr.get.similar.initials %>%
      ## disambr.get.similar.last.names %>% 
      ## disambr.get.same.affiliation
  ## dt[[7]]$same.affiliations


  ##' Returns set of people with save email addresses
  ##' @param sets 
  ##' @param procedures 
  ##' @inheritDotParams 
  ##' @return 
  ##' 
  ##' @md 
  ##' @importFrom magrittr %>%
  ##' @import magrittr data.table dplyr stringr
  ##' @export 
  disambr.get.3.refs.common <- function(sets, procedures = NULL) {
      message("Starting disambr.get.3.refs.common...")
      ## TODO: extract teh set that we need here (person, dyads)
      similar.last.names <- sets %>%
          extract(sapply(.,attr, "disambr.set.unit") == "similar.last.names") %>%
          extract2(1)
      set.data <-sets %>%
          extract(sapply(.,attr, "disambr.set.unit") == "person") %>%
          extract2(1)
      new.set <-
          similar.last.names %>% 
          dplyr::mutate(same.affiliations =
                            mapply(function(var1, var2)
                                any(set.data$author_affiliations[var1] %in% 
                                    set.data$author_affiliations[var2])
                            , Var1, Var2))
      ## new.set <- dplyr::filter(new.set, last.name.dist < 2)
      attributes(new.set)$disambr.set.unit <- "same.affiliation"
      return(c(sets, list(new.set)))
  }

  ## my.file2 <- "../data/new_export/savedrecs-ms-recent.txt"
  ## dt <- disambr.read(my.file2) %>%
      ## disambr.get.different.authors %>%
      ## disambr.get.similar.initials %>%
      ## disambr.get.similar.last.names %>% 
      ## disambr.get.same.affiliation
  ## dt[[7]]$same.affiliations
#+END_SRC

** get.file.extension                                                 :util:
:PROPERTIES:
:ID:       org:5dtbqwb0wri0
:END:

#+BEGIN_SRC R :tangle disambr_utils.r
## my own file.extention extractor
get.file.extension <- function(f) {
    if(length(f) == 1) {
        if(is.character(f)) {
            f %>% basename %>% 
                stri_split_fixed(".") %>% 
                extract2(1) %>%
                extract(ifelse(length(.) == 1, NA, length(.))) %>%
                ifelse(is.na(.), "", .)
        } else if(is.na(f)) {
            NA
        }
    } else {
        NULL
    }
}

get.file.extension(my.file)
get.file.extension(my.file1)
get.file.extension("sdfsdf....")
get.file.extension("sdf")
get.file.extension("")
get.file.extension(NULL)
get.file.extension(NA)
get.file.extension("...sdf...sdf.df...sd.")
get.file.extension(".")
get.file.extension(".....")

## build in
file_ext(my.file)
file_ext(my.file1)
file_ext("sdfsdf....")
file_ext("sdf")
file_ext("")
file_ext(NULL)
file_ext(NA)
file_ext("...sdf...sdf.df...sd.")
file_ext(".")
file_ext(".....")
#+END_SRC


*** experiments with read.wos

#+BEGIN_SRC R :results none :session :tangle no
  ## ------------------------------------------------------------------------------------
  ## Script that loads and refine raw data
  ## ------------------------------------------------------------------------------------

  ## Setting session ----
  rm(list = ls())
  setwd("/Users/Stan/Cloud/ECKM-15/Analysis in R")
  options(java.parameters = "-Xmx2g")  # Otherwise will be an error of few memory when reading big xlsx files

  ## Loading required packages ----
  library("xlsx")
  library("data.table")
  library(XML)
  ## library('pander')

  ## ------------------------------------------------------------------------------------
                # Reading list of data folders ----
  Data <- list(Folders = read.csv("/Users/Stan/Cloud/Data/Data List.csv"
                                       , stringsAsFactors = F))



  ## ------------------------------------------------------------------------------------
  ## TODO Reading list of WoS conferences ----
  ## TODO folder paths as variables in headings
  ## TODO Varaibles lables
  ## WoSConf <- read.xlsx2("/Users/Stan/Google Drive/ECKM'15/science-confs-1990-2014-dec.xlsx"
  ##                      , 1
  ##                      , header = TRUE)


  ## ------------------------------------------------------------------------------------
  ## Reading Proceedigs and Other Publications Data

  ### Reading contents of folders ----
  Data$Files.Pub <- list.files(Data$Folders$Folder.Path[Data$Folders$Type %in% c("Proceedings", "Publications")]
                                , full.names = T
                                , pattern = ".*\\.txt$")

  ### Reading files and combinng into the single datafame ----

  Pub <- lapply(Data$Files.Pub[1:30]
                , function(x) {
                  print(paste0(round(100 * which(Data$Files.Pub == x) / length(Data$Files.Pub), 0)
                               ,"% - Reading ", which(Data$Files.Pub == x), "th file from total ", length(Data$Files.Pub)
                               , " files. Time: ", Sys.time()))


                  data.table(File = x
                             , ReadedTime = Sys.time()
                             , read.table(x
                                          , header = F
                                          , sep = "\t"
                                          , fileEncoding = "UTF-16LE"
                                          , fill = T
                                          , quote = ""
                                          , comment.char=""
                                          , skip = 1
                                          , allowEscapes = T
                                          , stringsAsFactors = F))
                })


  Pub <- rbindlist(Pub)

  ## Name the variables ----
  ## Getting field names from some random file in list Data$Files.Pub
  setnames(Pub, c("File"
                  , "Added"
                  , as.character(read.table(Data$Files.Pub[sample(1:length(Data$Files.Pub), 1)]
                                            , nrows = 1
                                            , header = F
                                            , sep = "\t"
                                            , fileEncoding = "UTF-16",
                                            , stringsAsFactors = F))
                  , "Empty"))

  ## Read variables and discription from file (http://images.webofknowledge.com/WOK46/help/DII/h_fieldtags.html)
  Data$Names.Pub <- readHTMLTable(Data$Folders$Folder.Path[Data$Folders$Data.Name == "Names.Pub"], trim = TRUE)[[2]]
  names(Data$Names.Pub) <- c("Tag", "Name")

  #### MAYBE Make human names
  names(Pub)[!(names(Pub) %in% Data$Names.Pub$Tag)]


  ### Coding samples of publications data from data list ----
  Pub <- cbind(Data.Name = as.factor(Data$Folders$Data.Name[match(as.factor(sub("/[^/]*$","", Pub$File))
                                                                       , Data$Folders$Folder.Path)])
               , Pub)


  ## Saving raw data
  save(Pub, file = paste0("RData/Raw publications - ",Sys.Date(),".RData"))

  ## Filtering excessive fields and saving data
  Pub <- Pub[,.(Data.Name, PT, AU, AF, LA, DT, CT, CY, HO, CL, SP, C1, RP, FU, TC, PD, PY, UT)]  #  .() is alias for list() in datatables
  save(Pub, file =  paste0("RData/Publications set - ",Sys.Date(),".RData"))


  ## In case I want to do semantic networks
  ## DE                              #  Author Keywords
  ## ID                               #  Keywords Plus®
  ## WC                        # Web of Science Category
  ## SC                              # Subject Category

  ## In case I want to do citation analysis
  ## TI
  ## CR                             # Cited References
  ## NR                         # Cited Reference Count


  ## ------------------------------------------------------------------------------------
                # Reading Patent Data

  ## rm(Pub)

  ## Reading contents of folders ----
  Data$Files.Pat <- list.files(Data$Folders$Folder.Path[Data$Folders$Type %in% c("Patents")]
                                     , full.names = T
                                     , pattern = ".*\\.txt$")

  ## Reading files and combinng into the single datafame ----

  ## Function "fread" fails for some files in the list because they are proceedigs.. 
  ## I do not understand how it happent but these proceedings are in Pub table already
  ## Files that fail: Data$Files.Pat[c(484, 1394, 1832, 2176, 2415, 2579, 2587)]
  ## I use fread for speed..

  Data$Files.Pat <- Data$Files.Pat[-c(484, 1394, 1832, 2176, 2415, 2579, 2587)]

  Pat <- lapply(Data$Files.Pat[1:30]
                     , function(x) {
                       print(paste0(round(100 * which(Data$Files.Pat == x) / length(Data$Files.Pat), 0)
                                    ,"% - Reading ", which(Data$Files.Pat == x), "th file from total ", length(Data$Files.Pat)
                                    , " files. Time: ", Sys.time()))
                       data.table(File = x
                                  , Readed.Time = Sys.time()
                                  , fread(x
                                          , colClasses = rep("character", 24)
                                          , showProgress = F
                                          , verbose = F))
                     })

  Pat <- rbindlist(Pat)  # This sould be much faster than rbind


  ## TODO Name the variables
  ## Getting field names from some random file in list Data$Files.Pat
  setnames(Pat, c("File"
                  , "Added"
                  , gsub(" ","", as.character(fread(Data$Files.Pat[sample(1:length(Data$Files.Pat), 1)]
                                                    , nrows = 1
                                                    , header = F)))))

  ## Read variables and discription from file (http://images.webofknowledge.com/WOK46/help/DII/h_fieldtags.html)
  Data$Names.Pat <- readHTMLTable(Data$Folders$Folder.Path[Data$Folders$Data.Name == "Names.Pat"], trim = TRUE)[[4]]
  names(Data$Names.Pat) <- c("Tag", "Name")

  ## MAYBE Make human names
  names(Pat)[!(names(Pat) %in% Data$Names.Pat$Tag)]


  ## Coding samples of patents data from data list ----
  Pat <- cbind(Data.Name = as.factor(Data$Folders$Data.Name[match(as.factor(sub("/[^/]*$","", Pat$File))
                                                                       , Data$Folders$Folder.Path)])
               , Pat)

  ## Saving raw data
  save(Pat, file = paste0("RData/Raw patents - ",Sys.Date(),".RData"))

  ## Filtering excessive fields and saving data
  Pat <- Pat[,.(Data.Name, PN, AU, AE, GA, AD, PI)]
  save(Pat, file =  paste0("RData/Patents set - ",Sys.Date(),".RData"))

  ## Fields for citations analysis
  ## TI
  ## 20  CP                                      Cited Patent(s)
  ## 21  CR                                     Cited Article(s)

  ### Fields for classes and coveradge analysis
  ## 11  DC                                Derwent Class Code(s)
  ## 12  MC                               Derwent Manual Code(s)
  ## 13  IP                  International Patent Classification
  ## 18  DS                                    Designated States

#+END_SRC


